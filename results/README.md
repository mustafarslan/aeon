# Aeon Benchmark Results

This directory contains benchmark results for the Aeon Cognitive Operating System.

## Files

| File | Description |
|------|-------------|
| `benchmark_final.json` | Statistical benchmark results (auto-generated) |
| `README.md` | This documentation file |

## Benchmark Methodology

### Statistical Rigor

All benchmarks follow a strict statistical protocol:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| **Warm-up Iterations** | 10 | Prime CPU caches, stabilize branch predictors |
| **Measurement Iterations** | 50 | Statistical significance (95% confidence interval) |
| **Noise Threshold** | 10% | Flag environments with stddev/mean > 10% |
| **Latency Limit** | 200ms | Phase 0 constraint for Warm Search P99 |

### Metrics Collected

For each benchmark, we report:

- **Mean**: Average latency across all iterations
- **Median**: 50th percentile (robust to outliers)
- **P99**: 99th percentile (worst-case user experience)
- **Stddev**: Standard deviation (variance indicator)
- **Min/Max**: Range of observed values

### Benchmark Tests

| Test | Description | Target |
|------|-------------|--------|
| `MathKernel` | SIMD cosine similarity (768-dim) | < 100ns |
| `WarmSearch` | Atlas search with hot cache | < 200ms P99 |
| `ColdSearch` | Atlas search after cache flush | < 5ms |
| `ConversationalDrift` | SLB hit rate simulation | > 80% hits |

## Environment Requirements

### For Reproducible Results

1. **Close all applications** except terminal
2. **Disable background services** (cloud sync, indexing)
3. **Use wired power** (no battery throttling)
4. **Set CPU governor** to "performance" (Linux)

### Docker Clean Room

For maximum reproducibility, use the Docker benchmark container:

```bash
# Build the benchmark container
docker compose build aeon-bench

# Run benchmarks in isolated environment
docker compose run --rm aeon-bench
```

The container provides:

- CPU pinning to cores 0-3
- Memory locking (no swapping)
- Minimal background processes
- Consistent build environment

## Running Benchmarks

### Quick Run (Development)

```bash
# 3 warmup, 10 iterations
python scripts/verify_benchmarks.py --quick
```

### Full Run (Publication)

```bash
# 10 warmup, 50 iterations (default)
python scripts/verify_benchmarks.py
```

### Custom Configuration

```bash
python scripts/verify_benchmarks.py \
    --warmup 20 \
    --iterations 100
```

## Updating the Paper

After running benchmarks, inject results into LaTeX:

```bash
python scripts/update_paper.py
```

This creates `paper/paper_final.tex` with placeholders replaced by real values.

### Placeholder Format

In LaTeX source files, use:

```latex
The warm search latency is \VAR{warmsearch_p99}ms.
```

Available metrics (run with `--list-metrics` to see all):

| Placeholder | Description |
|-------------|-------------|
| `warmsearch_mean` | Warm search mean latency |
| `warmsearch_p99` | Warm search 99th percentile |
| `coldsearch_mean` | Cold search mean latency |
| `mathkernel_mean` | Math kernel mean latency |

## Interpreting Results

### Warning Signs

| Warning | Meaning | Action |
|---------|---------|--------|
| High variance (>10%) | Noisy environment | Close apps, retry |
| Warm Search > 200ms | Performance regression | Profile, optimize |
| Inconsistent P99 | System jitter | Use Docker container |

### Expected Ranges (M4 Max)

| Metric | Expected | Acceptable |
|--------|----------|------------|
| Math Kernel | 30-50 ns | < 100 ns |
| Warm Search | 0.5-2 ms | < 10 ms |
| Cold Search | 2-5 ms | < 20 ms |
| SLB Hit Rate | 80-90% | > 70% |

## Troubleshooting

### "Benchmark binary not found"

Build the C++ benchmarks first:

```bash
cmake --build build --target aeon_bench
```

### "aeon_py.core not found"

Install the Python package:

```bash
pip install -e .
```

### High variance on macOS

macOS has aggressive power management. Try:

```bash
# Prevent sleep during benchmarks
caffeinate -i python scripts/verify_benchmarks.py
```

## Data Format

`benchmark_final.json` structure:

```json
{
  "timestamp": "2026-01-14T13:45:00.000000",
  "platform": {
    "system": "Darwin",
    "machine": "arm64",
    "cpu_count": 16
  },
  "configuration": {
    "warmup_iterations": 10,
    "measurement_iterations": 50,
    "noise_threshold": 0.10,
    "latency_limit_ms": 200.0
  },
  "benchmarks": {
    "AtlasFixture/WarmSearch": {
      "name": "WarmSearch",
      "unit": "ms",
      "mean": 1.42,
      "median": 1.38,
      "p99": 2.15,
      "stddev": 0.23,
      "noise_warning": false
    }
  },
  "warnings": [],
  "passed": true,
  "failure_reason": null
}
```

---

*Generated by Aeon Benchmark Verification Suite*
