\section{System Architecture}
\label{sec:architecture}

Aeon implements a hybrid \textit{Cognitive Kernel} architecture designed to bridge the gap between high-performance systems programming and high-level AI reasoning. The system is architected to satisfy strict latency constraints ($< 200$ms end-to-end memory retrieval) while maintaining the flexibility required for complex agentic workflows.

% TODO: Insert Diagram of Core-Shell Memory Layout showing C++ Ring 0 and Python Ring 3 interacting via Shared Memory

\subsection{Design Philosophy: The Core-Shell Model}
The central design philosophy of Aeon is the \textit{Core-Shell} separation of concerns, ensuring that computational intensity and logical complexity are handled by the most appropriate runtime environments.

\begin{itemize}
    \item \textbf{The Core (Ring 0):} Implemented in C++23, the Core is responsible for all high-frequency, low-latency operations. This includes vector similarity search, tree traversal, and memory management. It operates directly on raw memory pages and leverages hardware acceleration (SIMD AVX-512) to maximize throughput.
    \item \textbf{The Shell (Ring 3):} Implemented in Python 3.12, the Shell manages high-level control logic, including Large Language Model (LLM) interaction, prompt engineering, and graph topology management. It serves as the "cognitive" layer that orchestrates the system's behavior.
\end{itemize}

The critical invariant of this architecture is the \textbf{Zero-Copy Constraint}: Data is never serialized or copied between the Core and the Shell during normal operation. Instead, ownership of data resides in the Core, and the Shell operates on read-only views of shared memory pages. This eliminates the marshaling overhead typical of foreign function interfaces (FFI).

\subsection{The Atlas: Spatial Memory Kernel}
The \textit{Atlas} is the foundational data structure of Aeon's long-term memory, functioning as a spatial index for semantic vectors. It is implemented as a specialized Hierarchical Navigable Small World (HNSW) variant, optimized for on-disk storage.

\subsubsection{Data Structure}
We define a memory node formally as a tuple $N$:
\begin{equation}
    N = \{id, \mathbf{v}, \mathcal{C}, \text{meta}\}
\end{equation}
where:
\begin{itemize}
    \item $id \in \mathbb{N}^{64}$ is a unique 64-bit identifier.
    \item $\mathbf{v} \in \mathbb{R}^{768}$ is the semantic embedding vector (occupying $768 \times 4$ bytes).
    \item $\mathcal{C}$ is the set of child pointers (offsets in the memory file).
    \item $\text{meta}$ is a fixed-size metadata block for timestamping and source tracking.
\end{itemize}

\subsubsection{Storage and Access}
The Atlas resides entirely on persistent storage (NVMe SSD) but is mapped into the process's virtual address space using the POSIX \texttt{mmap} system call. This allows the OS virtual memory subsystem to handle page caching transparently. We explicitly avoid standard C++ heap allocations (e.g., \texttt{new}, \texttt{malloc}) for node data to ensure data contiguity and cache locality.

\subsubsection{Greedy SIMD Descent}
Retrieval is performed using a \textit{Greedy SIMD Descent} algorithm. Given a query vector $\mathbf{q}$, and starting at a candidate node $n$, the algorithm computes the cosine similarity score $S_i$ for all children $i \in \mathcal{C}_n$:
\begin{equation}
    S_i = \cos(\mathbf{q}, \mathbf{c}_i) = \frac{\mathbf{q} \cdot \mathbf{c}_i}{\|\mathbf{q}\| \|\mathbf{c}_i\|}
\end{equation}
The system selects the next node $k = \arg\max_i S_i$ and recurses until a local optimum (leaf) is reached.
The complexity of this descent is $O(\log_B M)$, where $B$ is the effective branching factor and $M$ is the total number of nodes in the Atlas. All vector operations are vectorized using AVX-512 intrinsics, allowing 16 floating-point operations per cycle.

\subsection{The Trace: Episodic Context Graph}
While the Atlas provides spatial lookup, the \textit{Trace} provides temporal and causal context. It is structured as a Directed Acyclic Graph (DAG) $G = (V, E)$.

\subsubsection{Node Types}
The vertex set $V$ consists of heterogeneous node types representing different cognitive events:
\begin{itemize}
    \item $V_{user}$: Represents input from the human user.
    \item $V_{system}$: Represents responses generated by the agent.
    \item $V_{concept}$: Represents abstract semantic clusters retrieved from the Atlas.
\end{itemize}

\subsubsection{Edge Structure}
The edge set $E$ defines two primary relationship types:
\begin{enumerate}
    \item \textbf{Temporal Edges ($E_{next}$):} Provide the strict chronological sequence of the conversation. Traversing $E_{next}$ reconstructs the linear dialogue history.
    \item \textbf{Reference Edges ($E_{ref}$):} Connect episodic nodes to their semantic grounding in the Atlas. An edge $(u, a) \in E_{ref}$ implies that concept $a$ was active or referenced during event $u$.
\end{enumerate}

\subsubsection{Navigation}
The Trace enables the LLM to perform "backtracking." By traversing $E_{next}^{-1}$ (inverse temporal edges), the agent can effectively "rewind" its cognitive state to a previous turn to resolve ambiguities or correct context drift.

\subsection{The Zero-Copy Interface}
To strictly enforce the Zero-Copy Constraint, we utilize \texttt{nanobind} to expose C++ memory structures to Python. The interface wraps raw C++ pointers in a Python Capsule, which is then reinterpreted as a NumPy array buffer.

To ensure memory safety, the Python view is explicitly marked as \texttt{read\_only}. Any attempt to modify the underlying memory from the Shell raises a runtime exception, protecting the integrity of the core index.

% TODO: Insert optional pseudo-code block for C++ to Python memory mapping

\begin{algorithm}
\caption{Zero-Copy Memory Mapping}
\begin{algorithmic}
\State \textbf{Input:} C++ Vector $\mathbf{v}_{ptr}$
\State \textbf{Output:} Python NumPy Array $np\_view$
\State $capsule \leftarrow$ \texttt{PyCapsule\_New}($\mathbf{v}_{ptr}$, NULL)
\State $np\_view \leftarrow$ \texttt{PyArray\_FromBuffer}(capsule, dtype=\text{float32})
\State $np\_view$.flags.writeable $\leftarrow$ \textbf{False}
\State \Return $np\_view$
\end{algorithmic}
\end{algorithm}
